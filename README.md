I refactored the original monolithic design into a fully distributed microservice architecture to increase scalability, isolation, security, and maintainability. Instead of compiling and executing user-submitted code inside a single Node.js process, I split the system into four independent services: (1) an API gateway for receiving user submissions, (2) a Redis-backed asynchronous job queue layer, (3) language-specific worker services for C and Python execution, and (4) an S3 storage layer for code, test cases, and output persistence. The API service no longer performs heavy CPU work; it only validates input, uploads the raw code and test cases to S3, generates a submission ID, and enqueues a lightweight job reference into Redis (using separate queues for C and Python to enable language-based horizontal scaling). Worker services subscribe to their respective queues, pull jobs, fetch the source code and test cases from S3, and execute them inside isolated execution environments. Each worker handles compilation (gcc for C, Python interpreter for Python), and then runs the code against all provided test cases with strict execution timeouts. Execution results are uploaded back to S3, and job states are stored in Redis hashes (queued → compiling → running → completed). This architecture introduces real asynchronous processing, prevents API blocking, avoids concurrency issues, removes file conflicts, and allows any number of worker instances to be scaled up independently. Overall, my contribution transforms the system from a single-process compiler into a production-oriented distributed execution engine with clean separation of concerns, improved fault tolerance, parallelism, and maintainability.
